akka {
  actor {
    provider = "cluster"
    deployment {
      /node/processorRouter {
        router = round-robin-group
        routees.paths = ["/user/node/processor"]
        cluster {
          enabled = on
          allow-local-routees = on
        }
      }
    }
  }
  remote {
    log-remote-lifecycle-events = on
    netty.tcp {
      hostname = ${clustering.ip}
      port = ${clustering.port}
    }
  }
  cluster {
    seed-nodes = [
      "akka.tcp://"${clustering.cluster.name}"@"${clustering.seed-ip}":"${clustering.seed-port}
    ]
    auto-down-unreachable-after = 10s
  }
}
http {
  ip = "127.0.0.1"
  ip = ${?SERVER_IP}

  port = 8000
  port = ${?SERVER_PORT}
}
clustering {
  ip = "127.0.0.1"
  ip = ${?CLUSTER_IP}

  port = 2552
  port = ${?CLUSTER_PORT}

  seed-ip = "127.0.0.1"
  seed-ip = ${?CLUSTER_SEED_IP}

  seed-port = 2552
  seed-port = ${?CLUSTER_SEED_PORT}

  cluster.name = "ClusterArditi"
}


akka {
  io.dns.resolver = async-dns

  management {
    http {
      hostname = "127.0.0.1"
      hostname = ${?HOSTNAME}
      bind-hostname = "0.0.0.0"
      port = 8558
      bind-port = 8558
    }
    cluster.bootstrap {
      new-cluster-enabled = on
      contact-point-discovery {
        port-name = "management"
        protocol = "tcp"
        service-name = "application-dns-internal"
        discovery-method = akka-dns
      }
    }
  }
}

application {
  api {
    host = ${http.ip}
    port = ${http.port}
    hello-message = "Ameno Arditis!"
  }
}


akka {

  persistence {
    journal {
      plugin = "inmemory-journal" # "akka-contrib-mongodb-persistence-journal" # "cassandra-journal" #
      leveldb.native = false
    }
    snapshot-store {
      plugin = "inmemory-snapshot-store" # "akka-contrib-mongodb-persistence-snapshot" # "cassandra-snapshot-store" #
    }
  }
}
inmemory-read-journal {
  # Absolute path to the write journal plugin configuration section to get the event adapters from
  write-plugin = "inmemory-journal"

  # there are two modes; sequence or uuid. If set to "sequence" and NoOffset will be requested, then
  # the query will return Sequence offset types. If set to "uuid" and NoOffset will be requested, then
  # the query will return TimeBasedUUID offset types. When the query is called with Sequence then
  # the query will return Sequence offset types and if the query is called with TimeBasedUUID types then
  # the query will return TimeBasedUUID offset types.
  offset-mode = "sequence"

  # ask timeout on Futures
  ask-timeout = "10s"

  # New events are retrieved (polled) with this interval.
  refresh-interval = "100ms"

  # How many events to fetch in one query (replay) and keep buffered until they
  # are delivered downstreams.
  max-buffer-size = "100"
}

akka {
  # SBR
  cluster.downing-provider-class = "tanukki.akka.cluster.autodown.MajorityLeaderAutoDowning"
  custom-downing {
    stable-after = 10s

    majority-leader-auto-downing {
      majority-member-role = ""
      down-if-in-minority = true
      shutdown-actor-system-on-resolution = true
    }
  }
}


kafka.brokers = "0.0.0.0:9092"
kafka.brokers = ${?KAFKA_BROKERS_LIST}
include "kafka.conf"

akka {
  # options: OFF, ERROR, WARNING, INFO, DEBUG
  loglevel = "ERROR"
}